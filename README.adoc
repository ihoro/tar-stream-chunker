= tar-stream-chunker

image:https://github.com/ihoro/tar-stream-chunker.c/workflows/e2e-linux/badge.svg[link="https://github.com/ihoro/tar-stream-chunker.c/actions?query=workflow%3Ae2e-linux"]
image:https://github.com/ihoro/tar-stream-chunker.c/workflows/e2e-macos/badge.svg[link="https://github.com/ihoro/tar-stream-chunker.c/actions?query=workflow%3Ae2e-macos"]
image:https://github.com/ihoro/tar-stream-chunker.c/workflows/e2e-win/badge.svg[link="https://github.com/ihoro/tar-stream-chunker.c/actions?query=workflow%3Ae2e-win"]

Splits stdin onto chunk files and writes resulting TAR archive to stdout.

It can help to handle data stream of unknown size without hitting a disk. As long as creating TAR archive as a stream needs to know file size in advance, that is why the idea of the chunker is to split input stream onto chunks with known size.

Initial motivation was to use it for backup streaming to tarsnap.com.

== Build

Usual `make` should be enough, expecting you have a POSIX compliant system.

== Tests

Integration test suite is based on node.js:

`$ cd e2e; npm ci && npm test`

== Usage

`$ tar_stream_chunker { --file-name | -f } <file-name> { --chunk-size | -s } <bytes>`

And redirect its stdout to your target and that's it.

== Usage examples

PostgreSQL dump what is streamed to tarsnap:

`$ pg_dump | tar-stream-chunker -f dump.sql -s 500000000 | tarsnap -cvf dump.daily.$(date +%Y%m%d.%H%M%S) @-`

Let's see what's inside a resulting TAR:
```
$ cat 3MB-file | tar-stream-chunker --file-name file --chunk-size 1000000 > archive.tar
$ tar -tf archive.tar
file.00001
file.00002
file.00003
```

